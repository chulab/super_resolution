{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add `super_resolution` package.\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import predict\n",
    "from trainer import train\n",
    "from trainer import model as straight_model\n",
    "from trainer import angle_first_model\n",
    "from preprocessing import parser\n",
    "from preprocessing import input\n",
    "from simulation import create_observation_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_spec_path='/Users/noah/Documents/CHU/super_resolution/data/simulation/circle_3_18/observation_spec.json'\n",
    "\n",
    "predict_dataset_directory='/Users/noah/Documents/CHU/super_resolution/data/simulation/circle_3_18/predict'\n",
    "\n",
    "model_dir='/Users/noah/Documents/CHU/super_resolution/experiments/3_26_straight'\n",
    "model_type=\"STRAIGHT\"\n",
    "\n",
    "\n",
    "distribution_blur_sigma=1e-4\n",
    "observation_blur_sigma=1e-4\n",
    "distribution_downsample_size=(250, 250)\n",
    "observation_downsample_size=(250, 250)\n",
    "example_size=(501,501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_spec = create_observation_spec.load_observation_spec(observation_spec_path)\n",
    "\n",
    "predict_parse_fn = parser.Parser(\n",
    "observation_spec=observation_spec,\n",
    "reverse_rotation=True,\n",
    "distribution_blur_sigma=distribution_blur_sigma,\n",
    "observation_blur_sigma=observation_blur_sigma,\n",
    "distribution_downsample_size=distribution_downsample_size,\n",
    "observation_downsample_size=observation_downsample_size,\n",
    "example_size=example_size,\n",
    ").parse\n",
    "\n",
    "if model_type==train._STRAIGHT:\n",
    "    model=straight_model\n",
    "elif model_type==train._ANGLE_FIRST:\n",
    "    model=angle_first_model\n",
    "else:\n",
    "    raise ValueError('Not a valid model type. Got {}'.format(args.model_type))\n",
    "\n",
    "estimator_fn = model.build_estimator\n",
    "hparams = model.make_hparams()\n",
    "\n",
    "hparams['observation_spec'] = observation_spec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/noah/Documents/CHU/super_resolution/experiments/3_26_straight/model.ckpt-4060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/noah/Documents/CHU/super_resolution/experiments/3_26_straight/model.ckpt-4060\n"
     ]
    }
   ],
   "source": [
    "# Set up input\n",
    "predict_dataset = input.input_fn(\n",
    "      predict_dataset_directory,\n",
    "      predict_parse_fn,\n",
    "      1,\n",
    "      1,\n",
    "      1,\n",
    "      1,\n",
    "    )\n",
    "iterator = predict_dataset.make_one_shot_iterator()\n",
    "features, labels = iterator.get_next()\n",
    "\n",
    "# Load `RunConfig`.\n",
    "run_config = tf.estimator.RunConfig()\n",
    "run_config = run_config.replace(model_dir=model_dir)\n",
    "\n",
    "# Rebuild the model\n",
    "predictions = model.model_fn(features, labels, tf.estimator.ModeKeys.EVAL, hparams).predictions\n",
    "\n",
    "# Manually load the latest checkpoint\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    # Loop through the batches and store predictions and labels\n",
    "    prediction_values = []\n",
    "    label_values = []\n",
    "    for i in range(1):\n",
    "        try:\n",
    "            preds, lbls = sess.run([predictions, labels])\n",
    "            prediction_values += preds\n",
    "            label_values += lbls\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
